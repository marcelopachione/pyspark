{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eWu_SkHVs6zF"
      },
      "source": [
        "### Guide on How to Work with PySpark on Google Colab\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv6ZW5fItE_V"
      },
      "outputs": [],
      "source": [
        "# Connecting Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Setting up PySpark in Colab\n",
        "# 1. First task is to download Java.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# 2. Install Apache Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "\n",
        "!tar -xzvf /content/spark-3.4.0-bin-hadoop3.tgz\n",
        "\n",
        "# 3. Install and that is the findspark library. It will locate Spark on the system and import it as a regular library.\n",
        "!pip install -q findspark\n",
        "\n",
        "# 4. set the environment path. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n",
        "\n",
        "# 5. We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method.\n",
        "import findspark\n",
        "findspark.init('spark-3.4.0-bin-hadoop3')\n",
        "\n",
        "# 6. Now, we can import SparkSession from pyspark.sql and create a SparkSession, which is the entry point to Spark.\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark\n",
        "\n",
        "# 7. To view the Spark UI, you would have to include a few more lines of code to create a public URL for the UI page.\n",
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip ngrok-stable-linux-amd64.zip\n",
        "#get_ipython().system_raw('./ngrok http 4050 &')\n",
        "#!curl -s http://localhost:4040/api/tunnels"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPy9r4JJh5xut1e1nEQeILr",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
